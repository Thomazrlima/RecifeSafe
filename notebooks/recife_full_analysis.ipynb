{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5bb685",
   "metadata": {},
   "source": [
    "# Recife — Análise Completa (usando `real_data_converted.csv`)\n",
    "Este notebook executa um fluxo completo e comentado cobrindo: carregamento/limpeza, estatísticas, visualizações, regressão simples, análise de resíduos, treinamento e avaliação de classificadores simples (LogisticRegression, DecisionTree, KNN), além de interpretação e próximos passos.\n",
    "\n",
    "Execute as células sequencialmente. Se faltar alguma biblioteca, use a célula de instalação (próxima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Auto-instalação (opcional) — roda no kernel atual\n",
    "import sys\n",
    "import subprocess\n",
    "markdown\n",
    "cell-1\n",
    "markdown\n",
    "# Recife — Análise Completa (usando `real_data_converted.csv`)\n",
    "Este notebook executa um fluxo completo e comentado cobrindo: carregamento/limpeza, estatísticas, visualizações, regressão simples, análise de resíduos, treinamento e avaliação de classificadores simples (LogisticRegression, DecisionTree, KNN), além de interpretação e próximos passos.\n",
    "\n",
    "Execute as células sequencialmente. Se faltar alguma biblioteca, use a célula de instalação (próxima).\n",
    "code\n",
    "cell-2\n",
    "python\n",
    "# 0) Auto-instalação (opcional) — roda no kernel atual\n",
    "import sys\n",
    "import subprocess\n",
    "required = [\"numpy\", \"pandas\", \"matplotlib\", \"seaborn\", \"scikit-learn\", \"joblib\"]\n",
    "missing = []\n",
    "for pkg in required:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        missing.append(pkg)\n",
    "if missing:\n",
    "    print('Instalando:', missing)\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', *missing])\n",
    "    print('Instalação concluída — reinicie o kernel se necessário')\n",
    "else:\n",
    "    print('Dependências essenciais presentes')\n",
    "code\n",
    "cell-3\n",
    "python\n",
    "# 1) Imports e configurações visuais\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "markdown\n",
    "cell-4\n",
    "markdown\n",
    "## 2) Carregamento dos dados\n",
    "Usaremos `data/processed/real_data_converted.csv`. Se não existir, o notebook interrompe e mostra instruções.\n",
    "code\n",
    "cell-5\n",
    "python\n",
    "p = Path('..') / 'data' / 'processed' / 'real_data_converted.csv'\n",
    "if not p.exists():\n",
    "    raise FileNotFoundError(f\\\n",
    "print('Carregando', p)\n",
    "df = pd.read_csv(p, parse_dates=['date'], dayfirst=True)\n",
    "print('shape:', df.shape)\n",
    "display(df.head())\n",
    "code\n",
    "cell-6\n",
    "python\n",
    "# 2b) Sanity-check rápido: colunas, tipos, nulos, range de datas\n",
    "print('Colunas:', df.columns.tolist())\n",
    "display(df.dtypes.to_frame('dtype'))\n",
    "print('\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python -m pip install -r requirements.txtpython -m pip install --upgrade pip.\\.venv\\Scripts\\Activate.ps1python -m venv .venv```powershellSe precisar criar um ambiente virtual e instalar dependências, execute estes comandos no terminal (PowerShell):## 15) Como rodar rápido (PowerShell)markdowncell-29markdown- Explicabilidade (SHAP) e integração com dashboard (Streamlit/Folium).- Balanceamento de classes, calibração de probabilidades e busca por hiperparâmetros.- Engenharia de features espaciais (lat/lon), uso do solo, infraestrutura.- Validação temporal mais rigorosa (rolling-window/backtest).## 14) Pontos de melhoria e próximos passosmarkdowncell-28markdownprint('- Se custo de falsos negativos for alto, priorize recall e ajuste thresholds.')print('- Chuva acumulada (24h) é um preditor relevante; verifique interação com maré e vulnerabilidade.')print('\\nSíntese:')print('Métricas do melhor modelo:', {k:v for k,v in best[1].items() if k in ['acc','prec','rec','f1','auc']})print('Melhor modelo por F1:', best[0])best = max(results.items(), key=lambda kv: kv[1]['f1'])# Síntese automática (exemplo)pythoncell-27codeComente os pontos fortes/fracos dos modelos, trade-offs entre precisão e recall, e recomendações operacionais.## 13) Interpretação e síntesemarkdowncell-26markdownplt.show()plt.tight_layout()plt.legend()plt.title('Precision-Recall Curves')plt.ylabel('Precision')plt.xlabel('Recall')        plt.plot(rec_vals, prec_vals, label=name)        prec_vals, rec_vals, _ = precision_recall_curve(y_test_clf, r['y_proba'])    if r['y_proba'] is not None:for name, r in results.items():plt.subplot(1,2,2)plt.legend()plt.title('ROC Curves')plt.ylabel('True Positive Rate')plt.xlabel('False Positive Rate')plt.plot([0,1],[0,1],'k--')        plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.2f})\")        auc = r['auc'] if r['auc'] is not None else roc_auc_score(y_test_clf, r['y_proba'])        fpr, tpr, _ = roc_curve(y_test_clf, r['y_proba'])    if r['y_proba'] is not None:for name, r in results.items():plt.subplot(1,2,1)plt.figure(figsize=(12,5))pythoncell-25codePlot das curvas para os modelos que retornam probabilidades.## 12) Curvas ROC e Precision-Recallmarkdowncell-24markdown    print()        print('AUC:', r['auc'])    if r['auc'] is not None:    print('Confusion matrix:\\n', r['cm'])    print(f\"Accuracy: {r['acc']:.3f}, Precision: {r['prec']:.3f}, Recall: {r['rec']:.3f}, F1: {r['f1']:.3f}\")    print(f'--- {name} ---')for name, r in results.items():# Mostrar resumo    results[name] = dict(model=model, acc=acc, prec=prec, rec=rec, f1=f1, cm=cm, auc=auc, y_proba=y_proba, y_pred=y_pred)    auc = roc_auc_score(y_test_clf, y_proba) if (y_proba is not None and len(set(y_test_clf))>1) else None    cm = confusion_matrix(y_test_clf, y_pred)    f1 = f1_score(y_test_clf, y_pred, zero_division=0)    rec = recall_score(y_test_clf, y_pred, zero_division=0)    prec = precision_score(y_test_clf, y_pred, zero_division=0)    acc = accuracy_score(y_test_clf, y_pred)    y_proba = model.predict_proba(X_test_clf)[:,1] if hasattr(model, 'predict_proba') else None    y_pred = model.predict(X_test_clf)    model.fit(X_train_clf, y_train_clf)for name, model in models.items():results = {}}    'KNN': KNeighborsClassifier(n_neighbors=5)    'DecisionTree': DecisionTreeClassifier(random_state=42),    'Logistic': LogisticRegression(max_iter=1000),models = {X_test_clf = scaler.transform(X_test_clf)X_train_clf = scaler.fit_transform(X_train_clf)scaler = StandardScaler()    raise ValueError('Conjunto de treino ou teste vazio — verifique o split temporal e a coluna date')if X_train_clf.shape[0] == 0 or X_test_clf.shape[0] == 0:y_test_clf = df.loc[test_mask, 'risk_label'].valuesy_train_clf = df.loc[train_mask, 'risk_label'].valuesX_test_clf = df.loc[test_mask, features].fillna(0).valuesX_train_clf = df.loc[train_mask, features].fillna(0).valuestest_mask = df['date'] > split_datetrain_mask = df['date'] <= split_datesplit_date = df['date'].quantile(0.8)# Divisão temporal para classificaçãopythoncell-23codeUsaremos divisão temporal para reduzir vazamento: últimos 20% por data como teste.## 11) Classificação: treino (temporal), modelos simples e avaliaçãomarkdowncell-22markdownComente sobre o coeficiente, R^2 e padrão dos resíduos. Use este resultado como baseline.## 10) Interpretação dos resultados (regressão)markdowncell-21markdownprint('Resid mean:', residuals.mean(), 'Resid std:', residuals.std())plt.show()plt.title('Distribuição dos resíduos')sns.histplot(residuals, kde=True)plt.figure()residuals = yr_test - yr_pred# Resíduosplt.show()plt.title('Regressão linear simples')plt.legend()plt.ylabel('risk_index')plt.xlabel('rain_24h_sum')plt.plot(xs, lr.predict(xs), color='red', label='linha tendência')xs = np.linspace(X_reg.min(), X_reg.max(), 200).reshape(-1,1)plt.scatter(Xr_test, yr_test, alpha=0.6, label='observado')plt.figure()# Gráfico: dispersão + linha tendênciaprint('R^2 (teste):', lr.score(Xr_test, yr_test))print('Coeficiente:', lr.coef_[0], 'Intercept:', lr.intercept_)yr_pred = lr.predict(Xr_test)lr.fit(Xr_train, yr_train)lr = LinearRegression()Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)# Divisão aleatória 80/20 para regressão (exploratória)pythoncell-20code## 9) Regressão simples: treino/teste, linha de tendência e análise de resíduosmarkdowncell-19markdownprint('Classificação: X', X_clf.shape, 'y', y_clf.shape)print('Regressão: X', X_reg.shape, 'y', y_reg.shape)y_clf = df['risk_label'].valuesX_clf = df[features].fillna(0).valuesfeatures = ['rain_24h_sum','tide_12h_max','vuln_index','rain_lag_1']y_reg = df['risk_index'].valuesX_reg = df[['rain_24h_sum']].valuespythoncell-18code- Features exemplo: chuva acumulada, maré, lag, vulnerabilidade.- Classificação: target = `risk_label` (0/1)- Regressão: target = `risk_index` (contínuo)## 8) Definição de variáveis (X/y)markdowncell-17markdownprint('- Considere modelos multivariados para separar efeitos de maré e vulnerabilidade local.')print('- Chuva acumulada (24h) tende a estar positivamente associada ao risk_index; valide magnitude/significância.')print('\\nInterpretação (sintética):')    print('\\nColunas dayofweek ou rain_24h_sum ausentes para análise temporal')else:    print(daily)    print('\\nMédia de chuva 24h por dia da semana:')    daily = df.groupby('dayofweek')['rain_24h_sum'].mean()if 'dayofweek' in df.columns and 'rain_24h_sum' in df.columns:        print(f' - {a} <-> {b}: {v:.2f}')    for a, b, v in uniq:else:    print('  Nenhum par com |r|>0.5 encontrado.')if not uniq:print('Pares com |r|>0.5:')        seen.add((a, b)); uniq.append((a, b, v))    if (a, b) not in seen:for a, b, v in high:seen = set(); uniq = []# limpar duplicatas            high.append((pair[0], pair[1], float(corr.loc[i, j])))            pair = tuple(sorted([i, j]))        if i != j and abs(corr.loc[i, j]) > 0.5:    for j in corr.columns:for i in corr.columns:high = [])    raise NameError(\\if 'corr' not in globals():# Segurança: garantir que corr existapythoncell-16codeListamos pares com correlação absoluta > 0.5 e mostramos média de chuva por dia da semana.## 7) Identificação de padrões e correlações + interpretação automáticamarkdowncell-15markdownplt.show()plt.title('Correlação entre variáveis')sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')plt.figure(figsize=(8,6))corr = df[cols].corr()# Heatmap correlação entre cols selecionadasplt.show()plt.title('rain_24h_sum vs risk_index')sns.scatterplot(data=df.sample(min(len(df), 1000)), x='rain_24h_sum', y='risk_index', hue='neighborhood', alpha=0.6, s=30)plt.figure()# Scatter: rain_24h_sum vs risk_index (amostra para performance)pythoncell-14codeScatter plots e heatmap para investigar relações entre variáveis.## 6) Dispersões e mapa de calor (correlações)markdowncell-13markdownplt.show()plt.title('Mean risk_index por bairro')plt.xticks(rotation=45)sns.barplot(data=counts.sort_values('mean_risk', ascending=False), x='neighborhood', y='mean_risk')plt.figure()# Barra: mean risk_index por bairroplt.show()plt.title('Boxplot: maré (cm) por bairro')plt.xticks(rotation=45)sns.boxplot(data=df, x='neighborhood', y='tide_cm', order=order)order = df.groupby('neighborhood')['tide_cm'].median().sort_values().indexplt.figure(figsize=(12,6))# Boxplot maré por bairroplt.show()plt.xlabel('rain_24h_sum')plt.title('Distribuição da chuva 24h (mm)')sns.histplot(df['rain_24h_sum'].dropna(), bins=30, kde=True, color='tab:blue')plt.figure()# Histograma chuva 24hpythoncell-12codeHistogramas, boxplots por bairro e barras de risco médio por bairro.## 5) Visualizações: histogramas, boxplots e barrasmarkdowncell-11markdowndisplay(counts.sort_values('pct_high_risk', ascending=False))counts = df.groupby('neighborhood').agg(total_obs=('date','count'), mean_risk=('risk_index','mean'), pct_high_risk=('risk_label','mean')).reset_index()# Estatísticas por bairrodisplay(desc)desc['missing'] = df[cols].isna().sum().valuesdesc = df[cols].describe().Tcols = ['rain_mm','tide_cm','rain_24h_sum','rain_48h_sum','tide_12h_max','vuln_index','risk_index']pythoncell-10codeMédias, medianas, desvios e contagens por variável e por bairro.## 4) Estatísticas descritivas básicasmarkdowncell-9markdowndisplay(df.head())print('Preparação finalizada — colunas:', df.columns.tolist())df['risk_label'] = (df['risk_index'] > df['risk_index'].quantile(0.75)).astype(int)df['risk_index'] = 0.5 * df['rain_norm'] + 0.35 * df['tide_norm'] + 0.15 * df['vuln_norm']df['vuln_norm'] = df['vuln_index'] / (df['vuln_index'].max() + 1e-9)df['tide_norm'] = df['tide_12h_max'] / (df['tide_12h_max'].max() + 1e-9)df['rain_norm'] = df['rain_24h_sum'] / (df['rain_24h_sum'].max() + 1e-9)# Índice heurístico de risco e label (proxy)df['dayofweek'] = df['date'].dt.dayofweekdf['hour'] = df['date'].dt.hourdf['rain_lag_1'] = df.groupby('neighborhood')['rain_mm'].shift(1).fillna(0)df['tide_12h_max'] = df.groupby('neighborhood')['tide_cm'].rolling(window=2, min_periods=1).max().reset_index(level=0, drop=True)df['rain_48h_sum'] = df.groupby('neighborhood')['rain_mm'].rolling(window=8, min_periods=1).sum().reset_index(level=0, drop=True)df['rain_24h_sum'] = df.groupby('neighborhood')['rain_mm'].rolling(window=4, min_periods=1).sum().reset_index(level=0, drop=True)df = df.sort_values(['neighborhood', 'date']).reset_index(drop=True)# Ordenar e criar features temporais (assumimos amostragem regular; ajustar conforme necessário)    df['vuln_index'] = 0.5  # fallbackif 'vuln_index' not in df.columns:df['tide_cm'] = df.groupby('neighborhood')['tide_cm'].apply(lambda x: x.fillna(x.median()))df['rain_mm'] = df.groupby('neighborhood')['rain_mm'].apply(lambda x: x.fillna(x.median()))# Preencher nulos simples por mediana por bairro        raise ValueError(f'Coluna obrigatória ausente: {c}')    if c not in df.columns:for c in required:required = ['neighborhood', 'rain_mm', 'tide_cm']df['date'] = pd.to_datetime(df['date'])# Converter 'date' e checar colunas mínimaspythoncell-8codePadronizamos colunas essenciais e criamos lags/janelas rolantes. Ajuste as janelas caso a frequência temporal do CSV seja diferente.## 3) Limpeza e preparação de featuresmarkdowncell-7markdown    passexcept Exception:    print('\n",
    "Range de datas:', df['date'].min(), '->', df['date'].max())try:display(df.isna().sum().to_frame('n_missing'))Nulos por coluna:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão temporal para classificação\n",
    "split_date = df['date'].quantile(0.8)\n",
    "train_mask = df['date'] <= split_date\n",
    "test_mask = df['date'] > split_date\n",
    "X_train_clf = df.loc[train_mask, features].fillna(0).values\n",
    "X_test_clf = df.loc[test_mask, features].fillna(0).values\n",
    "y_train_clf = df.loc[train_mask, 'risk_label'].values\n",
    "y_test_clf = df.loc[test_mask, 'risk_label'].values\n",
    "\n",
    "if X_train_clf.shape[0] == 0 or X_test_clf.shape[0] == 0:\n",
    "    raise ValueError('Conjunto de treino ou teste vazio — verifique o split temporal e a coluna date')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_clf = scaler.fit_transform(X_train_clf)\n",
    "X_test_clf = scaler.transform(X_test_clf)\n",
    "\n",
    "models = {\n",
    "    'Logistic': LogisticRegression(max_iter=1000),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_clf, y_train_clf)\n",
    "    y_pred = model.predict(X_test_clf)\n",
    "    y_proba = model.predict_proba(X_test_clf)[:,1] if hasattr(model, 'predict_proba') else None\n",
    "    acc = accuracy_score(y_test_clf, y_pred)\n",
    "    prec = precision_score(y_test_clf, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test_clf, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test_clf, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_test_clf, y_pred)\n",
    "    auc = roc_auc_score(y_test_clf, y_proba) if (y_proba is not None and len(set(y_test_clf))>1) else None\n",
    "    results[name] = dict(model=model, acc=acc, prec=prec, rec=rec, f1=f1, cm=cm, auc=auc, y_proba=y_proba, y_pred=y_pred)\n",
    "\n",
    "# Mostrar resumo\n",
    "for name, r in results.items():\n",
    "    print(f'--- {name} ---')\n",
    "    print(f\"Accuracy: {r['acc']:.3f}, Precision: {r['prec']:.3f}, Recall: {r['rec']:.3f}, F1: {r['f1']:.3f}\")\n",
    "    print('Confusion matrix:\\n', r['cm'])\n",
    "    if r['auc'] is not None:\n",
    "        print('AUC:', r['auc'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f81625",
   "metadata": {},
   "source": [
    "## 12) Curvas ROC e Precision-Recall\n",
    "Plot das curvas para os modelos que retornam probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50644d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "for name, r in results.items():\n",
    "    if r['y_proba'] is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test_clf, r['y_proba'])\n",
    "        auc = r['auc'] if r['auc'] is not None else roc_auc_score(y_test_clf, r['y_proba'])\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.2f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for name, r in results.items():\n",
    "    if r['y_proba'] is not None:\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test_clf, r['y_proba'])\n",
    "        plt.plot(rec_vals, prec_vals, label=name)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb0ed9",
   "metadata": {},
   "source": [
    "## 13) Interpretação e síntese\n",
    "Comente os pontos fortes/fracos dos modelos, trade-offs entre precisão e recall, e recomendações operacionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7656a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Síntese automática (exemplo)\n",
    "best = max(results.items(), key=lambda kv: kv[1]['f1'])\n",
    "print('Melhor modelo por F1:', best[0])\n",
    "print('Métricas do melhor modelo:', {k:v for k,v in best[1].items() if k in ['acc','prec','rec','f1','auc']})\n",
    "\n",
    "print('\\nSíntese:')\n",
    "print('- Chuva acumulada (24h) é um preditor relevante; verifique interação com maré e vulnerabilidade.')\n",
    "print('- Se custo de falsos negativos for alto, priorize recall e ajuste thresholds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21967026",
   "metadata": {},
   "source": [
    "## 14) Pontos de melhoria e próximos passos\n",
    "- Validação temporal mais rigorosa (rolling-window/backtest).\n",
    "- Engenharia de features espaciais (lat/lon), uso do solo, infraestrutura.\n",
    "- Balanceamento de classes, calibração de probabilidades e busca por hiperparâmetros.\n",
    "- Explicabilidade (SHAP) e integração com dashboard (Streamlit/Folium)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53998c6b",
   "metadata": {},
   "source": [
    "## 15) Como rodar rápido (PowerShell)\n",
    "Se precisar criar um ambiente virtual e instalar dependências, execute estes comandos no terminal (PowerShell):\n",
    "```powershell\n",
    "python -m venv .venv\n",
    ".\\.venv\\Scripts\\Activate.ps1\n",
    "python -m pip install --upgrade pip\n",
    "python -m pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe6db1",
   "metadata": {},
   "source": [
    "# Localizações candidatas para o dataset (apenas 'simulated_daily.csv' conforme solicitado)\n",
    "base = Path('..') / 'data' / 'processed'\n",
    "candidates = [\n",
    "    base / 'simulated_daily.csv'\n",
    "]\n",
    "source\n",
    "if 'corr' not in globals():\n",
    "    raise NameError(\"Variável 'corr' não encontrada — rode a célula do heatmap antes desta.\")\n",
    "if not hasattr(corr, 'columns'):\n",
    "    raise TypeError(\"'corr' não parece ser um DataFrame com atributo .columns\")\n",
    "# Pares com correlação absoluta > 0.5\n",
    "high = []\n",
    "for i in corr.columns:\n",
    "    for j in corr.columns:\n",
    "        if i != j and abs(corr.loc[i, j]) > 0.5:\n",
    "            pair = tuple(sorted([i, j]))\n",
    "            high.append((pair[0], pair[1], float(corr.loc[i, j])))\n",
    "# limpar duplicatas\n",
    "seen = set()\n",
    "uniq = []\n",
    "for a, b, v in high:\n",
    "    if (a, b) not in seen:\n",
    "        seen.add((a, b))\n",
    "        uniq.append((a, b, v))\n",
    "print('Pares com |r|>0.5:')\n",
    "if not uniq:\n",
    "    print('  Nenhum par com |r|>0.5 encontrado.')\n",
    "else:\n",
    "    for a, b, v in uniq:\n",
    "        print(f' - {a} <-> {b}: {v:.2f}')\n",
    "# Padrões temporais simples (se colunas existirem)\n",
    "if 'dayofweek' in df.columns and 'rain_24h_sum' in df.columns:\n",
    "    daily = df.groupby('dayofweek')['rain_24h_sum'].mean()\n",
    "    print('')\n",
    "    print('Média de chuva 24h por dia da semana:')\n",
    "    print(daily)\n",
    "else:\n",
    "    print('\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Abaixo carregamos explicitamente `../data/processed/real_data_converted.csv`. Se o arquivo não existir, interrompemos e mostramos instruções.## 2) Carregamento e limpeza dos dados (apenas `real_data_converted.csv`)print('- Considere modelos multivariados para separar efeitos de maré e vulnerabilidade local.')print('- Chuva acumulada (24h) tende a apresentar correlação positiva com risk_index; verifique magnitude e significância estatística para confirmação.')print('\n",
    "Interpretação (sintética):')# Interpretação textual sintetizadaColunas para análise temporal ausentes: dayofweek ou rain_24h_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho explícito para usar apenas o arquivo simulated_daily.csv (conforme solicitado)\n",
    "p = Path('..') / 'data' / 'processed' / 'simulated_daily.csv'\n",
    "if not p.exists():\n",
    "    raise FileNotFoundError(f'Arquivo esperado não encontrado: {p}. Coloque o arquivo em data/processed com esse nome.')\n",
    "print('Carregando', p)\n",
    "df = pd.read_csv(p, parse_dates=['date'], dayfirst=True)\n",
    "# Mostrar informações básicas\n",
    "print('shape:', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964a044",
   "metadata": {},
   "source": [
    "## 3) Limpeza básica e preparação\n",
    "Padronizamos data, preenchemos ausentes simples e criamos features temporais necessárias (lags e janelas rolantes). Tudo comentado em cada passo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir formato de data e colunas mínimas\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "required = ['neighborhood','rain_mm','tide_cm']\n",
    "for col in required:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f'Coluna obrigatória ausente: {col}')\n",
    "# Preencher valores NaN simples por mediana por bairro quando apropriado\n",
    "df['rain_mm'] = df.groupby('neighborhood')['rain_mm'].apply(lambda x: x.fillna(x.median()))\n",
    "df['tide_cm'] = df.groupby('neighborhood')['tide_cm'].apply(lambda x: x.fillna(x.median()))\n",
    "# Se vuln_index não existir, preencher com mediana global ou com 0.5 como fallback\n",
    "if 'vuln_index' not in df.columns:\n",
    "    df['vuln_index'] = 0.5\n",
    "# Ordenar e criar features rolling/lags (assumimos frequência próxima a 6H — adaptar se necessário)\n",
    "df = df.sort_values(['neighborhood','date']).reset_index(drop=True)\n",
    "# rolling sums e maximas — ajustar min_periods conforme necessidade\n",
    "df['rain_24h_sum'] = df.groupby('neighborhood')['rain_mm'].rolling(window=4, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "df['rain_48h_sum'] = df.groupby('neighborhood')['rain_mm'].rolling(window=8, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "df['tide_12h_max'] = df.groupby('neighborhood')['tide_cm'].rolling(window=2, min_periods=1).max().reset_index(level=0, drop=True)\n",
    "df['rain_lag_1'] = df.groupby('neighborhood')['rain_mm'].shift(1).fillna(0)\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['dayofweek'] = df['date'].dt.dayofweek\n",
    "# Índice de risco heurístico (proxy) — manter como base para modelos caso não haja label real\n",
    "df['rain_norm'] = df['rain_24h_sum'] / (df['rain_24h_sum'].max() + 1e-9)\n",
    "df['tide_norm'] = df['tide_12h_max'] / (df['tide_12h_max'].max() + 1e-9)\n",
    "df['vuln_norm'] = df['vuln_index'] / (df['vuln_index'].max() + 1e-9)\n",
    "df['risk_index'] = 0.5 * df['rain_norm'] + 0.35 * df['tide_norm'] + 0.15 * df['vuln_norm']\n",
    "df['risk_label'] = (df['risk_index'] > df['risk_index'].quantile(0.75)).astype(int)\n",
    "print('Preparação finalizada — colunas:' , df.columns.tolist())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c9b73",
   "metadata": {},
   "source": [
    "## 4) Estatísticas descritivas básicas\n",
    "Médias, medianas, desvios e contagens por variável relevante e por bairro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbafb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['rain_mm','tide_cm','rain_24h_sum','rain_48h_sum','tide_12h_max','vuln_index','risk_index']\n",
    "desc = df[cols].describe().T\n",
    "desc['missing'] = df[cols].isna().sum().values\n",
    "display(desc)\n",
    "# Estatísticas por bairro\n",
    "counts = df.groupby('neighborhood').agg(total_obs=('date','count'), mean_risk=('risk_index','mean'), pct_high_risk=('risk_label','mean')).reset_index()\n",
    "display(counts.sort_values('pct_high_risk', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ae89a",
   "metadata": {},
   "source": [
    "## 5) Visualizações: histogramas, boxplots e gráficos de barras\n",
    "Visualizações com comentários para interpretação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma da chuva 24h\n",
    "plt.figure()\n",
    "sns.histplot(df['rain_24h_sum'], bins=30, kde=True, color='tab:blue')\n",
    "plt.title('Distribuição da chuva 24h (mm)')\n",
    "plt.xlabel('rain_24h_sum')\n",
    "plt.show()\n",
    "# Boxplot de maré por bairro\n",
    "plt.figure(figsize=(12,6))\n",
    "order = df.groupby('neighborhood')['tide_cm'].median().sort_values().index\n",
    "sns.boxplot(data=df, x='neighborhood', y='tide_cm', order=order)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Boxplot: maré (cm) por bairro')\n",
    "plt.show()\n",
    "# Barras: mean risk_index por bairro\n",
    "plt.figure()\n",
    "sns.barplot(data=counts.sort_values('mean_risk', ascending=False), x='neighborhood', y='mean_risk')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Mean risk_index por bairro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a6342",
   "metadata": {},
   "source": [
    "## 6) Dispersões e mapa de calor (correlações)\n",
    "Scatter plots e heatmap para investigar relações entre variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e111ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: chuva acumulada 24h vs risk_index\n",
    "plt.figure()\n",
    "sns.scatterplot(data=df, x='rain_24h_sum', y='risk_index', hue='neighborhood', alpha=0.6, s=40)\n",
    "plt.title('rain_24h_sum vs risk_index')\n",
    "plt.show()\n",
    "# Heatmap de correlação\n",
    "corr = df[cols].corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlação entre variáveis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc7dc6",
   "metadata": {},
   "source": [
    "## 7) Identificação de padrões e correlações (texto)\n",
    "Geramos um resumo automático dos pares com correlação alta para orientar interpretações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888017b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pares com correlação absoluta > 0.5\n",
    "high = []\n",
    "for i in corr.columns:\n",
    "    for j in corr.columns:\n",
    "        if i!=j and abs(corr.loc[i,j])>0.5:\n",
    "            pair = tuple(sorted([i,j]))\n",
    "            high.append((pair[0],pair[1],corr.loc[i,j]))\n",
    "# limpar duplicatas\n",
    "seen=set(); uniq=[]\n",
    "for a,b,v in high:\n",
    "    if (a,b) not in seen:\n",
    "        seen.add((a,b)); uniq.append((a,b,v))\n",
    "print('Pares com |r|>0.5:')\n",
    "for a,b,v in uniq:\n",
    "    print(f'{a} <-> {b}: {v:.2f}')\n",
    "# Padrões temporais simples\n",
    "daily = df.groupby('dayofweek')['rain_24h_sum'].mean()\n",
    "print('Média de chuva 24h por dia da semana:')\n",
    "print(daily)\n",
    "# Interpretação textual sintetizada\n",
    "print('Interpretação (sintética):')\n",
    "print('- Chuva acumulada (24h) tem correlação positiva com risk_index; confirma a hipótese de que eventos de chuva afetam risco.')\n",
    "print('- Ajustar modelos multivariados para capturar efeito de marés e vulnerabilidade local.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8866c919",
   "metadata": {},
   "source": [
    "## 8) Definição de variáveis dependente e independente\n",
    "- Regressão: `risk_index` (variável contínua)\n",
    "- Classificação: `risk_label` (0/1)\n",
    "- Features exemplo: chuva acumulada, maré, lag e vulnerabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar X/y\n",
    "X_reg = df[['rain_24h_sum']].values\n",
    "y_reg = df['risk_index'].values\n",
    "features = ['rain_24h_sum','tide_12h_max','vuln_index','rain_lag_1']\n",
    "X_clf = df[features].fillna(0).values\n",
    "y_clf = df['risk_label'].values\n",
    "print('Regressão: X', X_reg.shape, 'y', y_reg.shape)\n",
    "print('Classificação: X', X_clf.shape, 'y', y_clf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9fd784",
   "metadata": {},
   "source": [
    "## 9) Regressão simples: treino, linha de tendência e análise de resíduos\n",
    "Usamos LinearRegression para entender relação univariada entre chuva 24h e risk_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# divisão 80/20 aleatória — para análise exploratória; para produção usar divisão temporal\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "lr = LinearRegression()\n",
    "lr.fit(Xr_train, yr_train)\n",
    "yr_pred = lr.predict(Xr_test)\n",
    "print('Coeficiente:', lr.coef_[0], 'Intercept:', lr.intercept_)\n",
    "print('R^2 (teste):', lr.score(Xr_test, yr_test))\n",
    "# Visualizar\n",
    "plt.figure()\n",
    "plt.scatter(Xr_test, yr_test, alpha=0.6, label='observado')\n",
    "xs = np.linspace(X_reg.min(), X_reg.max(), 100).reshape(-1,1)\n",
    "plt.plot(xs, lr.predict(xs), color='red', label='linha tendência')\n",
    "plt.xlabel('rain_24h_sum')\n",
    "plt.ylabel('risk_index')\n",
    "plt.legend()\n",
    "plt.title('Regressão linear simples')\n",
    "plt.show()\n",
    "# Resíduos\n",
    "residuals = yr_test - yr_pred\n",
    "plt.figure()\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribuição dos resíduos')\n",
    "plt.show()\n",
    "print('Resid mean:', residuals.mean(), 'Resid std:', residuals.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096a5d8",
   "metadata": {},
   "source": [
    "## 10) Interpretação dos resultados (regressão)\n",
    "- O coeficiente indica variação esperada no `risk_index` por unidade de `rain_24h_sum`.\n",
    "- R^2 indica quanto da variância do target é explicada pela chuva univariada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d85011d",
   "metadata": {},
   "source": [
    "## 11) Classificação: treinar modelos simples e avaliar\n",
    "Treinamos LogisticRegression, DecisionTree e KNN. As métricas e gráficos seguem abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# divisão temporal simples para diminuir leakage: últimos 20% por data como teste\n",
    "split_date = df['date'].quantile(0.8)\n",
    "train_mask = df['date'] <= split_date\n",
    "test_mask = df['date'] > split_date\n",
    "# Seleção via DataFrame.loc para manter alinhamento e evitar ambiguidades\n",
    "features = ['rain_24h_sum','tide_12h_max','vuln_index','rain_lag_1']\n",
    "X_train_clf = df.loc[train_mask, features].fillna(0).values\n",
    "X_test_clf = df.loc[test_mask, features].fillna(0).values\n",
    "y_train_clf = df.loc[train_mask, 'risk_label'].values\n",
    "y_test_clf = df.loc[test_mask, 'risk_label'].values\n",
    "# Verificar se temos dados suficientes\n",
    "if X_train_clf.shape[0] == 0 or X_test_clf.shape[0] == 0:\n",
    "    raise ValueError('Conjunto de treino ou teste vazio — verifique as datas e o split temporal.')\n",
    "# Escalar\n",
    "scaler = StandardScaler()\n",
    "X_train_clf = scaler.fit_transform(X_train_clf)\n",
    "X_test_clf = scaler.transform(X_test_clf)\n",
    "models = {'Logistic': LogisticRegression(max_iter=1000), 'DecisionTree': DecisionTreeClassifier(random_state=42), 'KNN': KNeighborsClassifier(n_neighbors=5)}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_clf, y_train_clf)\n",
    "    y_pred = model.predict(X_test_clf)\n",
    "    y_proba = model.predict_proba(X_test_clf)[:,1] if hasattr(model, 'predict_proba') else None\n",
    "    acc = accuracy_score(y_test_clf, y_pred)\n",
    "    prec = precision_score(y_test_clf, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test_clf, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test_clf, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_test_clf, y_pred)\n",
    "    auc = roc_auc_score(y_test_clf, y_proba) if (y_proba is not None and len(set(y_test_clf))>1) else None\n",
    "    results[name] = dict(model=model, acc=acc, prec=prec, rec=rec, f1=f1, cm=cm, auc=auc, y_proba=y_proba, y_pred=y_pred)\n",
    "# Mostrar resumo\n",
    "for name, r in results.items():\n",
    "    print(f'--- {name} ---')\n",
    "    print(f\"Accuracy: {r['acc']:.3f}, Precision: {r['prec']:.3f}, Recall: {r['rec']:.3f}, F1: {r['f1']:.3f}\")\n",
    "    print('Confusion matrix:\\n', r['cm'])\n",
    "    if r['auc'] is not None:\n",
    "        print('AUC:', r['auc'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a3230",
   "metadata": {},
   "source": [
    "## 12) Curvas ROC e Precision-Recall (visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ce076",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "for name, r in results.items():\n",
    "    if r['y_proba'] is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test_clf, r['y_proba'])\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC={r['auc']:.2f})')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "for name, r in results.items():\n",
    "    if r['y_proba'] is not None:\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test_clf, r['y_proba'])\n",
    "        plt.plot(rec_vals, prec_vals, label=name)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a021ef4",
   "metadata": {},
   "source": [
    "## 13) Interpretação dos resultados (classificação)\n",
    "Observações: comparar precisão/recall conforme custo de falsos positivos vs falsos negativos; considerar reamostragem se classes desequilibradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd78068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de síntese automática simples\n",
    "best = max(results.items(), key=lambda kv: kv[1]['f1'])\n",
    "print('Melhor modelo por F1:', best[0])\n",
    "print('Métricas do melhor modelo:', {k:v for k,v in best[1].items() if k in ['acc','prec','rec','f1','auc']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73a17ec",
   "metadata": {},
   "source": [
    "## 14) Síntese dos achados principais\n",
    "- Chuva acumulada 24h aparece como preditor relevante do índice de risco; maré e vulnerabilidade também contribuem.\n",
    "- Modelos simples oferecem baseline; escolher modelo final com base em recall/precision conforme objetivo operacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdde113",
   "metadata": {},
   "source": [
    "## 15) Pontos de melhoria e próximos passos\n",
    "- Validação temporal mais rigorosa (rolling-window/backtest).\n",
    "- Incluir features espaciais (lat/lon, uso do solo).\n",
    "- Balanceamento de classes e busca de hiperparâmetros.\n",
    "- Explicabilidade (SHAP) e integração com dashboard (Streamlit/Folium)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
